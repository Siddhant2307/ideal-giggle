{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imgprojectNBC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML/PeNA/H7vXeJMXnKbyTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddhant2307/ideal-giggle/blob/master/imgprojectNBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzgLpM-heuTj",
        "outputId": "bcff4000-8e4f-4cfa-dd1a-5b993ca7ecb8"
      },
      "source": [
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "(trainX,trainy),(testX,testy)=fashion_mnist.load_data()\n",
        "def load_dataset():\n",
        "  (trainX,trainy),(testX,testy)=fashion_mnist.load_data()\n",
        "  trainX=trainX.reshape((trainX.shape[0],28,28,1))\n",
        "  testX=testX.reshape((testX.shape[0],28,28,1))\n",
        "  trainy=to_categorical(trainy)\n",
        "  testy=to_categorical(testy)\n",
        "  return trainX,trainy,testX,testy\n",
        "np.unique(trainy)\n",
        "\n",
        "seed=2\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "data_split=StratifiedShuffleSplit(test_size=0.75,random_state=seed)\n",
        "for train_index,test_index in data_split.split(trainX,trainy):\n",
        "    split_data_65,split_data_35=trainX[train_index],trainX[test_index]\n",
        "    split_label_65,split_label_35=trainy[train_index],trainy[test_index]\n",
        "train_test_split=StratifiedShuffleSplit(test_size=0.3,random_state=seed)\n",
        "for train_index,test_index in train_test_split.split(split_data_65,split_label_65):\n",
        "    train_data_70,test_data_30=split_data_65[train_index],split_data_65[test_index]\n",
        "    train_label_70,test_label_30=split_label_65[train_index],split_label_65[test_index]\n",
        "train_data=train_data_70\n",
        "train_label=train_label_70\n",
        "test_data=test_data_30\n",
        "test_label=test_label_30\n",
        "print(\"train data :\",train_data.shape)\n",
        "print(\"train label : \",train_label.shape)\n",
        "print(\"test data :\",test_data.shape)    \n",
        "print(\"test label : \",test_label.shape)\n",
        "class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "\n",
        "train_data=train_data.astype('float64')/255.0\n",
        "test_data=test_data.astype('float64')/255.0\n",
        "\n",
        "train_data_flat=train_data.reshape(train_data.shape[0],-1)\n",
        "test_data_flat=test_data.reshape(test_data.shape[0],-1)\n",
        "print(\"train data flat :\",train_data_flat.shape)\n",
        "print(\"test data flat :\",test_data_flat.shape)\n",
        "train_data_flat_t=train_data_flat\n",
        "test_data_flat_t=test_data_flat\n",
        "train_data_flat_t=train_data_flat\n",
        "test_data_flat_t=test_data_flat"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "train data : (10500, 28, 28)\n",
            "train label :  (10500,)\n",
            "test data : (4500, 28, 28)\n",
            "test label :  (4500,)\n",
            "train data flat : (10500, 784)\n",
            "test data flat : (4500, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cERMaQwYe56J",
        "outputId": "a1a78965-1697-40f7-c771-4683746b34ec"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "train_data_pca=PCA(n_components=min(train_data.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca=PCA(n_components=min(test_data.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10500, 28)\n",
            "(4500, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngPX2qtHe-LY",
        "outputId": "d3b09d5a-f009-4402-c41a-fcec12cfeb27"
      },
      "source": [
        "from skimage import color\n",
        "def svdFeatures(input_data):\n",
        "  svdArray_input_data=[]\n",
        "  size=input_data.shape[0]\n",
        "  for i in range(0,size):\n",
        "    U,s,V=np.linalg.svd(input_data[i],full_matrices=False)\n",
        "    S=[s[i] for i in range(28)]\n",
        "    svdArray_input_data.append(S)\n",
        "    svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
        "  return svdMatrix_input_data\n",
        "\n",
        "train_data_svd=svdFeatures(train_data)\n",
        "test_data_svd=svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10500, 28)\n",
            "(4500, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cEGnojqfBh3",
        "outputId": "87e76ab7-dfbd-44d2-f0fa-7de201e73f14"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb1 = GaussianNB()\n",
        "train = gnb1.fit(train_data_flat_t, train_label)\n",
        "\n",
        "\n",
        "y_pred1 = gnb1.predict(test_data_flat_t)\n",
        "score1 = gnb1.score(test_data_flat_t, test_label)\n",
        "print(\"score\", score1)\n",
        "\n",
        "Confusion_Matrix1 = metrics.confusion_matrix(test_label, y_pred1)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score 0.5624444444444444\n",
            "Confusion Matrix [[251  43  18  94  20   0   7   0  17   0]\n",
            " [  1 431   4   9   1   0   4   0   0   0]\n",
            " [  0  14 202  35 180   0  14   0   5   0]\n",
            " [  1 291   2 150   3   0   2   0   1   0]\n",
            " [  2  27  37  71 308   0   3   0   2   0]\n",
            " [  0   0   1   0   0 126   0 310   4   9]\n",
            " [ 36  38  63 108 160   0  18   0  27   0]\n",
            " [  0   0   0   0   0   2   0 442   0   6]\n",
            " [  1   5  28  37  42   3   7   1 326   0]\n",
            " [  0   0   0   0   0  11   4 154   4 277]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp3f_ij6fGCj",
        "outputId": "bbf9a7f2-8db5-407d-bdbd-f30cd553aedc"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb2 = GaussianNB()\n",
        "train = gnb2.fit(train_data_pca, train_label)\n",
        "\n",
        "\n",
        "y_pred2 = gnb2.predict(test_data_pca)\n",
        "score2 = gnb2.score(test_data_pca, test_label)\n",
        "print(\"score\", score2)\n",
        "\n",
        "Confusion_Matrix2 = metrics.confusion_matrix(test_label, y_pred2)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score 0.6275555555555555\n",
            "Confusion Matrix [[352   0   8  30   1   5  42   0  12   0]\n",
            " [ 14 305  37  48   4  11   8   0  23   0]\n",
            " [  1   0 255   4  55  12  94   0  29   0]\n",
            " [ 75  18   2 260  14   9  32   0  40   0]\n",
            " [  7   0 106  27 245   3  55   0   7   0]\n",
            " [  1   0   1   1   0 304   1  78  31  33]\n",
            " [ 86   0  65  11 109  13 152   0  14   0]\n",
            " [  0   0   0   0   1 146   4 214  39  46]\n",
            " [  0   0  24   7   8  21  15  27 346   2]\n",
            " [  0   0   0   0   1  19   2  16  21 391]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJwBmEtAfKv0",
        "outputId": "0346515d-117f-488e-b645-ba7115452645"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb3 = GaussianNB()\n",
        "train = gnb3.fit(train_data_svd, train_label)\n",
        "\n",
        "\n",
        "y_pred3 = gnb3.predict(test_data_svd)\n",
        "score3 = gnb3.score(test_data_svd, test_label)\n",
        "print(\"score\", score3)\n",
        "\n",
        "Confusion_Matrix3 = metrics.confusion_matrix(test_label, y_pred3)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score 0.296\n",
            "Confusion Matrix [[ 47 103  20  54  44   8   8 122   2  42]\n",
            " [  0 422   1   0   3   1   1  19   0   3]\n",
            " [ 17  97  48  36  75   0   8 132   7  30]\n",
            " [  1 312   1   1   3   2   0 119   0  11]\n",
            " [ 10  61  32  12 142   7   3 129   5  49]\n",
            " [  3 127   0   0   1  69   1 168   2  79]\n",
            " [ 24  58  29  18  85  19  15 122  14  66]\n",
            " [  0 161   0   0   0   2   0 267   0  20]\n",
            " [ 10  68  14  17  37  23   9 107  70  95]\n",
            " [  5   1   0   0  11  19   5 158   0 251]]\n"
          ]
        }
      ]
    }
  ]
}